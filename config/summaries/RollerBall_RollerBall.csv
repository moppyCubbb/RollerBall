Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Is Training
10000,1.4037002,12.286852589641434,0.5441937,0.5957446808510638,0.5957446808510638,0.08103199,0.24849983,0.00026952842,1.0
20000,1.395845,9.327479338842975,0.94032955,0.9886363636363636,0.9886363636363636,0.008307919,0.24053398,0.00020983278,1.0
30000,1.3853847,7.524296675191816,0.95076257,0.9872122762148338,0.9872122762148338,0.0082324,0.24657588,0.0001501086,1.0
40000,1.3679602,6.470500373412995,0.9648162,0.9940253920836445,0.9940253920836445,0.0034520973,0.2441768,9.015008e-05,1.0
50000,1.3624034,6.192805755395684,0.965799,0.99568345323741,0.99568345323741,0.002741181,0.23917423,3.0087034e-05,1.0
